{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "89b6aa48-05a7-4987-99c6-c06ced24396d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: radon in /student/eln263/.local/lib/python3.10/site-packages (6.0.1)\n",
      "Requirement already satisfied: mando<0.8,>=0.6 in /student/eln263/.local/lib/python3.10/site-packages (from radon) (0.7.1)\n",
      "Requirement already satisfied: colorama>=0.4.1 in /usr/local/anaconda3/lib/python3.10/site-packages (from radon) (0.4.6)\n",
      "Requirement already satisfied: six in /usr/local/anaconda3/lib/python3.10/site-packages (from mando<0.8,>=0.6->radon) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install radon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c1f0fef5-a3b7-49ec-8145-cdfb51e31153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to /student/eln263/Desktop/SF/ChuanhuChatGPT/ChuanhuChatGPT-20240305/output/xlsx/pylint_data.xlsx\n",
      "Data saved to /student/eln263/Desktop/SF/ChuanhuChatGPT/ChuanhuChatGPT-20240305/output/xlsx/pylint_data.xlsx\n",
      "Data saved to /student/eln263/Desktop/SF/ChuanhuChatGPT/ChuanhuChatGPT-20240305/output/xlsx/radon_data.xlsx\n",
      "Radon data corrected and saved to /student/eln263/Desktop/SF/ChuanhuChatGPT/ChuanhuChatGPT-20240305/output/xlsx/radon_data.xlsx\n",
      "Merged data saved to /student/eln263/Desktop/SF/ChuanhuChatGPT/ChuanhuChatGPT-20240305/output/xlsx/merged1.xlsx\n"
     ]
    }
   ],
   "source": [
    "from pylint.lint import Run\n",
    "from io import StringIO\n",
    "import os\n",
    "from radon.raw import analyze as raw_analyze\n",
    "from radon.complexity import cc_visit\n",
    "from radon.metrics import h_visit\n",
    "from radon.visitors import HalsteadVisitor\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "from radon.visitors import ComplexityVisitor\n",
    "from radon.metrics import mi_visit\n",
    "from radon.raw import analyze\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def ensure_directory_exists(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def get_python_files(directory):\n",
    "    python_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                full_path = os.path.join(root, file)\n",
    "                python_files.append(full_path)\n",
    "    return python_files\n",
    "\n",
    "def run_pylint_on_files(files, output_file_path):\n",
    "    pylint_args = files + ['--output-format=json']\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = StringIO()\n",
    "\n",
    "    try:\n",
    "        Run(pylint_args)\n",
    "    except SystemExit as e:\n",
    "        print(f\"Pylint exited with {e.code}\")\n",
    "    finally:\n",
    "        pylint_output = sys.stdout.getvalue()\n",
    "        sys.stdout = original_stdout\n",
    "\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        output_file.write(pylint_output)\n",
    "\n",
    "def parse_json_string(json_str):\n",
    "    decoder = json.JSONDecoder()\n",
    "    idx = 0\n",
    "    json_objects = []\n",
    "\n",
    "    while idx < len(json_str):\n",
    "        try:\n",
    "            obj, end = decoder.raw_decode(json_str[idx:])\n",
    "            json_objects.append(obj)\n",
    "            idx += end\n",
    "        except json.JSONDecodeError:\n",
    "            break\n",
    "\n",
    "    return json_objects\n",
    "\n",
    "\n",
    "def parse_pylint_output(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    pylint_data = parse_json_string(content)\n",
    "\n",
    "    issues = []\n",
    "    for item in pylint_data:\n",
    "        # If the item is a list (which seems to be the case based on the error), iterate through it\n",
    "        if isinstance(item, list):\n",
    "            for sub_item in item:\n",
    "                issues.append(parse_issue(sub_item))\n",
    "        else:  # Assuming item is a dict\n",
    "            issues.append(parse_issue(item))\n",
    "\n",
    "    return issues\n",
    "\n",
    "\n",
    "def parse_issue(item): #pylint output\n",
    "    \"\"\"Extract issue data from a dict.\"\"\"\n",
    "    return {\n",
    "        \"file\": item.get('path', 'N/A'),\n",
    "        \"message_id\": item.get('message-id', 'N/A'),\n",
    "        \"symbol\": item.get('symbol', 'N/A'),\n",
    "        \"category\": item.get('type', 'N/A'),\n",
    "        \"module_name\": item.get('module', 'N/A'),\n",
    "        \"line\": item.get('line', 'N/A'),\n",
    "        \"column\": item.get('column', 'N/A')\n",
    "    }\n",
    "\n",
    "\n",
    "def write_pylint_output_to_excel(issues, output_file_path):\n",
    "    df = pd.DataFrame(issues)\n",
    "    df.to_excel(output_file_path, index=False, engine='openpyxl')\n",
    "    print(f\"Data successfully written to {output_file_path}\")\n",
    "\n",
    "def run_radon_on_files(file_path): #radon output\n",
    "    results = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Analyze raw metrics\n",
    "        raw_metrics = raw_analyze(content)\n",
    "\n",
    "        # Analyze cyclomatic complexity\n",
    "        cc_results = cc_visit(content)\n",
    "\n",
    "        # Analyze Halstead metrics\n",
    "        h_report = h_visit(content)\n",
    "\n",
    "        # Calculate maintainability index\n",
    "        mi_metrics = mi_visit(content, multi=True)\n",
    "\n",
    "        # Directly use Radon's complexity scores\n",
    "        complexity_metrics = [{\n",
    "            'name': item.name,\n",
    "            'cyclomatic_score': item.complexity,\n",
    "            # Simplifying the output, not categorizing into rank or risk\n",
    "            'block_type': 'F' if hasattr(item, 'complexity') else 'N/A',  # F for function, simplification\n",
    "        } for item in cc_results if hasattr(item, 'complexity')]\n",
    "\n",
    "        metrics = {\n",
    "            'file_path': file_path,\n",
    "            'complexity': complexity_metrics,\n",
    "            'raw': raw_metrics._asdict(),\n",
    "            'halstead': {\n",
    "                'h1': h_report.total.h1,\n",
    "                'h2': h_report.total.h2,\n",
    "                'N1': h_report.total.N1,\n",
    "                'N2': h_report.total.N2,\n",
    "                'vocabulary': h_report.total.vocabulary,\n",
    "                'length': h_report.total.length,\n",
    "                'calculated_length': h_report.total.calculated_length,\n",
    "                'volume': h_report.total.volume,\n",
    "                'difficulty': h_report.total.difficulty,\n",
    "                'effort': h_report.total.effort,\n",
    "                'time': h_report.total.time,\n",
    "                'bugs': h_report.total.bugs,\n",
    "            },\n",
    "            'maintainability_index': mi_metrics,\n",
    "        }\n",
    "\n",
    "        results.append(metrics)\n",
    "\n",
    "    except IOError as e:\n",
    "        print(f\"Error opening or reading file {file_path}: {e}\")\n",
    "    return results\n",
    "\n",
    "def aggregate_radon_metrics(python_files):\n",
    "    all_metrics = [run_radon_on_files(file_path) for file_path in python_files]\n",
    "    return all_metrics\n",
    "\n",
    "\n",
    "def save_to_excel(aggregated_metrics, output_file_path):\n",
    "    columns = [\n",
    "        'file', 'type', 'line', 'column', 'name', 'complexity_rank',\n",
    "        'complexity_score', 'loc', 'lloc', 'sloc', 'comments', 'single_comments',\n",
    "        'multi', 'blank', 'h1', 'h2', 'N1', 'N2', 'vocabulary', 'length',\n",
    "        'calculated_length', 'volume', 'difficulty', 'effort', 'time',\n",
    "        'bugs', 'maintainability_index'\n",
    "    ]\n",
    "    data = []\n",
    "\n",
    "    # Helper function to safely convert to int, defaulting to default on failure\n",
    "    def safe_int(value, default=0):\n",
    "        try:\n",
    "            return int(value)\n",
    "        except ValueError:\n",
    "            return default\n",
    "\n",
    "    for file_metrics in aggregated_metrics:\n",
    "        for metrics in file_metrics:\n",
    "            complexity_metrics = metrics['complexity']\n",
    "            halstead_metrics = metrics['halstead']\n",
    "            raw_metrics = metrics['raw']\n",
    "            mi_metrics = metrics['maintainability_index']\n",
    "\n",
    "            for func_metrics in complexity_metrics:\n",
    "                # Apply safe_int to ensure lloc, loc, and sloc are integers\n",
    "                lloc = safe_int(func_metrics.get('lloc', 0))\n",
    "                loc = safe_int(func_metrics.get('loc', 0))\n",
    "                sloc = safe_int(func_metrics.get('sloc', 0))\n",
    "\n",
    "                row = {\n",
    "                    'file': metrics['file_path'],\n",
    "                    'type': 'Function' if lloc > 0 else 'Module',\n",
    "                    'name': func_metrics['name'],\n",
    "                    'complexity_rank': 'N/A',  # Define your own logic or leave as 'N/A'\n",
    "                    'complexity_score': func_metrics['cyclomatic_score'],\n",
    "                    'loc': loc,\n",
    "                    'lloc': lloc,\n",
    "                    'sloc': sloc,\n",
    "                    'comments': raw_metrics['comments'],\n",
    "                    'single_comments': 'N/A',  # Update if single line comments info is available\n",
    "                    'multi': raw_metrics['multi'],\n",
    "                    'blank': raw_metrics['blank'],\n",
    "                    'h1': halstead_metrics['h1'],\n",
    "                    'h2': halstead_metrics['h2'],\n",
    "                    'N1': halstead_metrics['N1'],\n",
    "                    'N2': halstead_metrics['N2'],\n",
    "                    'vocabulary': halstead_metrics['vocabulary'],\n",
    "                    'length': halstead_metrics['length'],\n",
    "                    'calculated_length': halstead_metrics['calculated_length'],\n",
    "                    'volume': halstead_metrics['volume'],\n",
    "                    'difficulty': halstead_metrics['difficulty'],\n",
    "                    'effort': halstead_metrics['effort'],\n",
    "                    'time': halstead_metrics['time'],\n",
    "                    'bugs': halstead_metrics['bugs'],\n",
    "                    'maintainability_index': mi_metrics,\n",
    "                }\n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.to_excel(output_file_path, index=False, engine='openpyxl')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def ensure_directory_exists(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def correct_excel(pylint_excel_output_path, radon_excel_output_path):\n",
    "    try:\n",
    "        # Read data from the radon Excel file\n",
    "        radon_data = pd.read_excel(radon_excel_output_path)\n",
    "        pylint_data = pd.read_excel(pylint_excel_output_path)\n",
    "\n",
    "        radon_data['file'] = radon_data['file'].str.replace(r'\\\\', '/', regex=True).str.replace('//', '/')\n",
    "    \n",
    "        #pylint_data['file'] = pylint_data['file'].str.replace(r'\\\\', r'\\\\\\\\', regex=True)\n",
    "        \n",
    "        # Replace backslashes with forward slashes in the 'file' column\n",
    "        #radon_data['file'] = radon_data['file'].str.replace('\\\\', '/')\n",
    "        # radon_data['file'] = radon_data['file'].apply(lambda x: re.sub(r'^.*maltrail-master', 'maltrail-master', x).replace('\\\\', '/'))\n",
    "        #radon_data['file'] = radon_data['file'].str.replace('/', '\\\\').replace('\\\\', '\\\\\\\\')\n",
    "\n",
    "        # Save the corrected data back to the same Excel file\n",
    "        radon_data.to_excel(radon_excel_output_path, index=False)\n",
    "        \n",
    "        print(f\"Radon data corrected and saved to {radon_excel_output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error correcting Radon Excel: {e}\")\n",
    "\n",
    "\n",
    "def merge_excel(pylint_excel_output_path ,radon_excel_output_path,merged_output_path):\n",
    "    # Load the data from the Excel files\n",
    "    pylint_data = pd.read_excel(pylint_excel_output_path)\n",
    "    radon_data = pd.read_excel(radon_excel_output_path)\n",
    "\n",
    "    # Clean and standardize the data for merging\n",
    "    # Now using 'file' as the common column for both\n",
    "    # pylint_data['file'] = pylint_data['file'].str.strip().str.lower().astype(str)\n",
    "    # radon_data['file'] = radon_data['file'].str.strip().str.lower().astype(str)\n",
    "\n",
    "    # Perform the merge operation using 'file' as the common column\n",
    "    #merged_data = pd.merge(pylint_data, radon_data, on='file', how='outer', suffixes=('_pylint', '_radon'))\n",
    "    merged_data = pd.merge(pylint_data, radon_data, on='file', how='inner')\n",
    "\n",
    "    # Check if the merge resulted in an empty DataFrame\n",
    "    if not merged_data.empty:\n",
    "        # Save the merged DataFrame to a new Excel file\n",
    "        merged_data.to_excel(merged_output_path, index=False)\n",
    "        print(f\"Merged data saved to {merged_output_path}\")\n",
    "    else:\n",
    "        print(\"No matching data found for merge. Please check the 'file' column for matching values.\")\n",
    "\n",
    "\n",
    "#directory_path = \"D:/GCIS_Project/Data/data_extracted/recommenders-main/recommenders-1.1.1\"\n",
    "directory_path = \"/student/eln263//Desktop/SF/ChuanhuChatGPT/ChuanhuChatGPT-20240305\"\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "target_directory = directory_path\n",
    "pylint_output_path = \"/student/eln263/Desktop/SF/ChuanhuChatGPT/ChuanhuChatGPT-ChuanhuChatGPT-20240305/output/json/pylint_output.json\"  # Changed to JSON\n",
    "pylint_excel_output_path = \"/student/eln263/Desktop/SF/ChuanhuChatGPT/ChuanhuChatGPT-20240305/output/xlsx/pylint_data.xlsx\"\n",
    "\n",
    "\n",
    "ensure_directory_exists(pylint_output_path)\n",
    "ensure_directory_exists(pylint_excel_output_path)\n",
    "\n",
    "files_to_lint = get_python_files(target_directory)\n",
    "run_pylint_on_files(files_to_lint, pylint_output_path)\n",
    "issues = parse_pylint_output(pylint_output_path)\n",
    "write_pylint_output_to_excel(issues, pylint_excel_output_path)\n",
    "print(f'Data saved to {pylint_excel_output_path}')\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "radon_output_path = \"/student/eln263/Desktop/SF/ChuanhuChatGPT/ChuanhuChatGPT-20240305/output/json/radon_output.json\"  # Changed to JSON\n",
    "radon_excel_output_path = \"/student/eln263/Desktop/SF/ChuanhuChatGPT/ChuanhuChatGPT-20240305/output/xlsx/radon_data.xlsx\"\n",
    "\n",
    "\n",
    "\n",
    "ensure_directory_exists(radon_output_path)\n",
    "ensure_directory_exists(radon_excel_output_path)\n",
    "\n",
    "files_to_radon = get_python_files(target_directory)\n",
    "metrics_radon = aggregate_radon_metrics(files_to_radon)\n",
    "save_to_excel(metrics_radon, radon_excel_output_path)\n",
    "\n",
    "print(f'Data saved to {radon_excel_output_path}')\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "last_name = os.path.basename(directory_path),\n",
    "if isinstance(last_name, tuple):\n",
    "    last_name = last_name[0]\n",
    "\n",
    "correct_excel(pylint_excel_output_path, radon_excel_output_path)\n",
    "\n",
    "\n",
    "#correct_excel(pylint_excel_output_path, radon_excel_output_path)\n",
    "merged_output_path = \"/student/eln263/Desktop/SF/ChuanhuChatGPT/ChuanhuChatGPT-20240305/output/xlsx/merged1.xlsx\"\n",
    "\n",
    "\n",
    "merge_excel(pylint_excel_output_path, radon_excel_output_path, merged_output_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b4f679-12f1-4293-8795-c1ed5d12bb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
